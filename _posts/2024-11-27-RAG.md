---
layout: post
title: RAG
categories: [RAG, LLM, GenAI] 
---

## Apache Spark / How does it work? 

1. AWS Glue is based on Apache Spark. 
1. until an action called there will not be any actual execution


## AWS Glue 

1. https://docs.aws.amazon.com/glue/

1. AWS Glue is a **serverless data integration** service 
1. integrate data from multiple sources. 
1. It also includes additional productivity and data ops tooling for authoring, running jobs, and implementing business workflows.
1. With AWS Glue, you can discover and connect to more than 
1. 70 diverse data sources and manage your data in a **centralized data catalog**. 
1. You can visually create, run, and monitor extract, transform, and load (ETL) pipelines 
1. to load data into your data lakes. 
1. immediately search and query cataloged data using Amazon Athena, Amazon EMR, and Amazon Redshift Spectrum.
1. AWS Glue consolidates major data integration capabilities into a single service. 
1. These include data discovery, modern ETL, cleansing, transforming, and centralized cataloging. 
1. It's also serverless, which means there's no infrastructure to manage. 
1. With flexible support for all workloads like ETL, ELT, and streaming in one service, AWS Glue supports users across various workloads and types of users.
1. Also, AWS Glue makes it easy to integrate data across your architecture. 
1. It integrates with AWS analytics services and Amazon S3 data lakes. 
1. AWS Glue has integration interfaces and job-authoring tools that are easy to use for 

1. ability to scale on demand, 
1. AWS Glue helps you focus on high-value activities that maximize the value of your data. 
1. It scales for any data size, and supports all data types and schema variances. 
1. To increase agility and optimize costs, AWS Glue provides built-in high availability and pay-as-you-go billing.

1. With AWS Glue, you pay an 
1. hourly rate, billed by the second, 
1. for crawlers (discovering data) and extract, transform, and load (ETL) jobs (processing and loading data). 
1. For the AWS Glue Data Catalog, you pay a simplified monthly fee for storing and accessing the metadata. 
1. The first million objects stored are free, and the first million accesses are free. 
1. a development endpoint to interactively develop your ETL code, 
1. you pay an hourly rate, billed per second. 
1. For AWS Glue DataBrew, the interactive sessions are billed per session, and DataBrew jobs are billed per minute. 
1. Usage of the AWS Glue Schema Registry is offered at no additional charge.


## Glue job / How to debug? 

1. https://stackoverflow.com/questions/68781443/how-to-debug-an-aws-glue-pyspark-job
1. AWS Glue is based on Apache Spark
1. [Debugging demanding stages and straggler tasks](https://docs.aws.amazon.com/glue/latest/dg/monitor-profile-debug-straggler.html)


## PySpark For AWS Glue Tutorial

- https://www.youtube.com/watch?v=DICsZiwuHJo

## AWS Glue Tutorial for Beginners

1. [AWS Glue Tutorial for Beginners [NEW 2024 - FULL COURSE]](https://www.youtube.com/watch?v=ZvJSaioPYyo)
1. Fully managed ETL service 








## Step by step no-code RAG application using Langflow.

1. https://www.youtube.com/watch?v=RWo4GDTZIsE
1. Langflow 
1. Langflow is a low-code tool for developers 
1. build powerful AI agents and workflows that can use any API, model, or database.
1. [langflow code](https://github.com/langflow-ai/langflow)
1. Langflow is a low-code app builder for RAG and multi-agent AI applications. It’s Python-based and agnostic to any model, API, or database.
1. [Langflow free cloud service](https://astra.datastax.com/signup?type=langflow)
1. [Welcome to Astra, kaun](https://astra.datastax.com/org/3e89fe60-0b63-4339-aca9-d4baaca01fb0)
1. [DataStax Langflow Docs](https://docs.datastax.com/en/langflow/index.html)

1. [OpenAI developer platform](https://platform.openai.com/docs/overview)
1. [Astra DB Serverless - database-as-a-service (DBaaS) - Apache Cassandra®, an open-source NoSQL distributed database](https://docs.datastax.com/en/astra-db-serverless/databases/create-database.html)
    1. Designed for vector search applications, such as Generative AI (GenAI) and semantic search
    1. can load vectors directly with your data 
    1. or, automatically generate vector embeddings with vectorize



## Youtube videos 

1. What are the infrastructure required. 
1. RODE - do you need that bada$$ mike? why? 
1. How do you show your screen and yet have yourself as an inset? 


## Augmenting LLMs Using Retrieval Augmented Generation by Nvidia 

1. Generative Pre-trained Transformer (GPT) 
1. LLM Fine Tuning vs. RAG 
1. Llama Index 
1. E5 large - embedding model 

## OpenAI / Swarm  

1. Swarm is an experimental, open-source Python framework from OpenAI 
1. that helps developers build, orchestrate, and deploy multi-agent systems:


## RAG vs Agentic RAG: A Comprehensive Guide 

1. https://www.analyticsvidhya.com/blog/2024/11/rag-vs-agentic-rag/

1. LLM without RAG 
1. The knowledge of RAG is constrained 
1. Large Language Model (LLM) on its own has a predefined training dataset that serves as its “internal knowledge.” 
1. You would like to add to its knowledge somehow 
1. Fine Tuning a LLM or a RAG 

1. **RAG (Retrieval-Augmented Generation)**
1. RAG is a framework LLM uses to get relevant, up-to-date, and context-specific information 
1. by combining retrieval and generation capabilities.



The process flow of an Agentic RAG System for handling user queries. Here’s a breakdown of each component:

## What the f**k is Agentic RAG? 

Agentic RAG refers to a more intelligent and dynamic Retrieval-Augmented Generation system where 
Agentic: The system works on its own, making decisions and taking actions depending on the situation.

1. an “agent” plays a key role in orchestrating processes. 
1. The agent intelligently determines which resources or databases are most relevant for a user’s query, 
1. making it capable of handling more complex, multi-tasking scenarios. 
It is an evolution from traditional RAG systems, 
offering greater adaptability and decision-making by incorporating additional logic or heuristics into the retrieval and response generation pipeline.
RAG (Retrieval-Augmented Generation): It mixes information from a knowledge base with the AI’s ability to create responses.



## What is Agentic Design Patterns?

1. https://www.analyticsvidhya.com/blog/2024/10/agentic-design-patterns/
1. The agentic design pattern is introduced as a solution for making LLMs more autonomous. 
1. Instead of just giving the model one prompt and expecting a final answer (like writing an essay in one go), 
1. an agent-like approach involves prompting the LLM multiple times, step by step. 
1. Each step refines the task, with the model improving its output iteratively.
1. When we prompt an LLM in zero-shot mode, it’s like asking someone to write a story in one go without revising. 
1. LLMs do well at this, but they can do even better. 
1. By using an agent-like workflow, we can prompt the LLM multiple times in steps. 
1. Each step builds on the previous one, refining the response. 
1. Think of it like asking the LLM to go over the essay multiple times, improving it with each pass.


## Example of usage of Agentic Design Pattern 

1. writing a code using Agentic workflow: 
Plan an outline for the code: Break down the task into smaller modules or functions.
Gather information and content: Research libraries, algorithms, or existing solutions. Do web searches or check the documentation if needed.
Write the first draft of the code: Implement the basic functionality, focusing on structure over perfection.
Review the code for inefficiencies or errors: Check for unnecessary code, bugs, or logic flaws.
Revise the code: Refactor, optimise, or add comments for clarity.
Rinse and repeat until the code is efficient and clean.


## What is the criteria for Retrieval ? 

## What is a Vector Database ? Why is it important for Agentic RAG ? 



## How does Agentic RAG system work? How does it handle user queries? 

1. The system receives a user query.
1. Does the query fit the criteria for retrieval (it is part of the vector database).