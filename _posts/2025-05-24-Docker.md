---
layout: post
title: Docker
categories: [Docker] 
---

## [Linkedin learning : Docker ](https://www.linkedin.com/learning/learning-docker-17236240/create-a-docker-container-from-dockerfiles-part-2?autoSkip=true&contextUrn=urn%3Ali%3AlyndaLearningPath%3A65eb4388345061d17bc1cba4&resume=false)


1. Which docker image to use? What is available? 

```
docker search python
```
    1. You can use filer option with a lot of variations.

1. I have found one. Pull it to my machine. 

```
docker image pull python // this will use the latest version, that is generally not used. 
docker image pull python:3.12-rc-bookworm

```
1. More information available at https://hub.docker.com/_/python
1. Now that I have downloaded, which all images do I have. 
``` 
docker image ls 
docker image ls --all 
```

1. **tags** - distinct versions of the same image 
1. build with -t option. 
```
docker build -t big-star . // no tags means it is the latest 
docker build --no-cache -t big-star:v1 -t big-star . // this is the tried and tested one. make one with v1 and one without anything to publish that as the latest as well. 
```

1. **lables** - searchable metadata about an image 

1. Docker hub **repository** / **registry** - 


1. Get a list of all the docker running 

1. and the ones that are not running too 

```
docker ps 
docker ps -a // this is the all option. 
docker ps -aq // show all, but only the names, not the whole table. 
docker stop xxx // stop the xxx container. Gracefully. 
docker stop -t 0 xxx // Stop now. Data loss? I dont care. 
```



1. Docker build 

```cmd
docker build --help 
docker build [OPTIONS] PATH | URL 

docker build . // build from the dockerfile in the current directory 
docker build -f [dockerfile] . // in case you have multiple dockerfiles for QA, NON-PROD, PRO etc. 
```

```
docker build --force-rm=true . 
```
1. This removes any temporary / intermediate containers 
1. These are created for each instructions in the Dockerfile e.g. RUN, COPY etc. 
1. Once the command is run, that is saved as a new image layer.
1. --force-rm=true removes any such intermediate layer, even if the build is unsuccessful. 

``` 
docker build --rm=true .
```
1. If build is unsuccessful, the intermediate containers will not be removed. 
1. helps in debugging the failed builds. 

```
docker build --no-cache . 
```
1. All previously build image layers are cached, for reuse. 
1. If the installation depends on external resources ( such as ???) the cached layer can be an issue ( why ???)
1. It is clean build but might take a long time. See what fits. 


## Docker start 
1. You must have done Docker build before it. 

## Docker run 
1. It does both Docker build && Docker run 

```
docker run [OPTIONS] IMAGE[:TAG] [COMMAND] [ARG...]
```
1. If there is a default command in the dockerfile, you dont have to provide command here during Docker run. 

```
docker run -it ...
```
1. Docker should run in interactive mode and allocates a pseudo tty 

```
docker run -d ...
```
1. Run in detached (-d) mode. It is a server or something with a long runtime. Let it run in the background. 

## Docker ps 

1. list all the containers that exited with code 137, i.e. were killed. 
```
docker ps -a --filter 'exited=137'
```

## Docker inspect 
```
docker inspect [OPTIONS] NAME|ID [NAME|ID...] 
```

## docker logs 
```
docker logs [OPTIONS] CONTAINER 
```
1. from the STDOUT and STDERR 

```
docker logs --tail 1000 -f my-container 
```

1. --tail - Show 1000 lines from the end of the logs. 
1. -f - follow the log output 


## docker volume create my-app-volume 

1. Data storage by docker. Directory on the host machine. 
1. Volume and the data stored in it persists, even if container is deleted. 
1. Same volume can be mounted to different containers. So they can interact. 


```
docker volume ls // list all the docker volumes 
docker volume inspect my-volume // inspect the volume. When was it created. Where is it. etc. 
docker volume rm my-volume // remove the volume, assuming volume is not in use. 

```

1. attach a volume to a container 
```
docker run -v volume:insidefolder imagename:tag // 
```

1. mention the volume in the dockerfile
```
// this is the dockerfile
VOLUME /app/data 
``` 


## Bind mount 
1. The data inside the bind mount WILL BE LOST when the container is deleted. 
1. They are used to share code and configuration between the host machine and container during development and testing. 

```
docker run -v "$(PWD)/test"/target:/app/test my-app:v2  
docker run --mount type=bind,source="$(PWD)/test",target=/app/test my-app:v2 
```

## docker image prune 
1. Clean up any dangling images. Images that are not tagged. 
1. That are not referenced by any container. 

```
docker system prune --volume -f  
```

1. Learning Docker Compose by Nicole Rifkin is an excellent resource for you to learn more.


1. Stop and remove the container in one line 

```
docker rm xxx // will not remove the container that are running 
docker stop && docker rm // instead of two commands you could ...
docker rm -f xxx // will removed running container 
```
1. One command to remove all the containers 
```
docker ps -aq | xargs docker rm
```

1. Images are big. They can take a lot of space. Remove them with rmi. 
```
docker images // list all the images 
docker image ls 
docker rmi xxx // remove the xxx image. If it is being used by a running container, it will not be removed. 
docker rmi -f xxx // Doing it forcibly. Might have unpredictable results. 
```

1. **Port binding**
1. Port binding. Take a port of the actual machine and bind it to a port of the container. 
``` 
docker run xxx 
docker run --name chunnu xxx // now I have given it a name 
docker run -d --name chunnu xxx // now I am running it in the background. Useful for running servers. 
docker run -d --name chunnu -p 5001:5000 xxx // binding my 5001 to 5000 of image 
```

1. **Volume mounting** 
1. Containers are disposable. When you dispose it, you are disposing the data as well. 
```
docker run --rm //  run and them rm for immediately remove. 
docker run --rm --entrypoint sh //  just run a shell command 
docker run --rm --entrypoint sh ubuntu //  there is no Dockerfile. Use the ubuntu image.
docker run --rm --entrypoint sh ubuntu -c "echo 'Hello there' > /tmp/file && cat /tmp/file" // echo hello into a tmp file and cat it. 
```
1. The echo will be printed, but since container was immediately removed, you will not find the tmp file. 
1. So you mount a folder by --v outsidefolder:insidefolder 
```
docker run --rm --entrypoint sh --volume /tmp/container:/tmp ubuntu -c "echo 'Hello there' > /tmp/file && cat /tmp/file" // mount a Volume
```

1. **Container image registry** 
1. Create an account on Docker hub 

1. **Login**
```
docker login 
username 
password 
``` 
1. Then tag it 

```
docker tag xxx username/xxx:version 
docker tag my-web-server kaunjovi/my-web-server:0.0.1
docker push kaunjovi/my-web-server:0.0.1
```

## How to ensure that the Docker image that  you are using is safe? 
1. Use "official" versions. 
1. If you must use un-official versions, scan them with 
    1. Clair 
    1. Trivy 
    1. Dagda 

## Docker Compose 
1. **How to run multiple connected containers on a single machine?**
1. **How to deploy a three tier web application using Docker?** 
1. For any non trivial application, it is likely to have multiple components. 
1. DONT put all of them in a single Docker. It is not meant for that kind of usage. 
1. You could manually create multiple Docker and connect all of them, 
    1. you could use virtual networks and mounted volumes. 
    1. but IT IS TOO MUCH work. Time consuming and Error prone. 
1. Use **Docker compose** instead. 
1. ?? Read more. 

## Kubernetes - Planet scale container orchestrator 
1. **What are Container Orchestrators? What are they used for?**
1. It is a distributed system. Run and store data across many machines. So it can connect with 100,000s of containers. 
1. It can run on almost anything - starting from raspberry pi - to the largest of machines. 
1. It helps manage traffic to and fro your containers. 


## https://guide.bash.academy/



# [Linkedin certification on Docker by Shelley Benhoff](https://www.linkedin.com/learning/docker-your-first-project/setting-up-your-development-environment?autoSkip=true&contextUrn=urn%3Ali%3AlyndaLearningPath%3A65eb4388345061d17bc1cba4&resume=false)

1. Download and install Docker Desktop 
    1. VSCode 
    1. VSCode extension for Docker. 
1. https://github.com/LinkedInLearning/docker-your-first-project-4485003

```
Add changes to git using this command: git add .
Commit changes using this command: git commit -m "some message"
```

```
Clone this repository into your local machine using the Git Bash command git clone https://github.com/LinkedInLearning/docker-your-first-project-4485003.git
Switch between branches using the Git Bash command git checkout CHAPTER#_MOVIE#
View all available branches using the Git Bash command git branch
```

# Dockerfile cheatsheet 

```Dockerfile
# This is a comment. 

# FROM what base image to use:the specifict tag. Avoid latest, which is the default. 
# The base image should have the tools needed to run the application.   
# You can look them up in https://hub.docker.com/repositories/parthaittech
FROM python:3.12-rc-bookworm


WORKDIR /app

COPY . /app 

# Do not store the downloaded files in the cache. Download them anew each time? 
RUN pip install --no-cache-dir -r requirements.txt 

# Set environment variables. Flask needs some. 
ENV FLASK_APP=app.py

# Run this command by default. 
CMD ["flask", "run", "--host=0.0.0.0" ]

```





1. Command : docker build 

```
docker build 
docker build -t our-first-docker-image 

// What is the name of the docker file? If it is not Dockerfile, spell that out. 
docker build -t our-first-docker-image -f app.Dockerfile 
docker build -t our-first-docker-image --file app.Dockerfile

// Where is the context. Is it in the same folder. Just put a dot. 
docker build -t our-first-docker-image . 


```

1. Docker images are layers of images over one another. 
1. So, for every command it creates an impage. So, should we try to use less command? Might be. 
1. These are called intermediate images. 
1. Once it is created you can run it. 

```
docker run our-first-docker-image 
```

1. **What if the container does not exit immediately after execution?** 
1. Build the docker image. Use server.Dockerfile. Context is current folder (.). 
```
docker build --file server.Dockerfile --tag our-first-docker-server . 
docker run our-first-docker-server 
```
1. find the name of the docker and kill it 
```
docker ps 
docker kill xxx 
```
1. This time, be smart. Run it as -d. Make it run in background. 
```
docker run -d our-first-docker-server 
```
1. Huh?? I did something. Did not understand 
```
docker exec xxx date 
```
1. And now we are getting freaky. We are running bash in intereactive mode in the image. 


```
docker exect --intereactive --tty xxx bash 
```



1. **USER command of Linux Ubuntu**
1. root 
1. nobody 


# Docker Compose. Configuration as code. 
1. Docker configuration as YAML code. 
1. It is Declarative and NOT Procedural. 
1. Declarative - you tell what is the intended end step. 
1. Procedural - you tell the steps to be taken. 

1. It is good for 
    1. Local development
    1. Staging server 
    1. Testing environment

1. It is NOT good for 
    1. Complex production environments. 
    1. Distributed systems 
    1. Any place where scaling of one component is required, while the other components remain unchanged.
    1. Use **Docker Swarm** or **Kubernetes** for production environments. 

1. **docker-compose.yaml**

```yaml
version: "3.9"

services: 
    my-service-one:
        build: .        //use the dockerfile of the folder. This is called the Context. 
    my-service-two:
        image: "mysql"  // use the latest?? mysql impage from the registry. 
```

## docker-compose up 
1. Build, create, and start 
1. You could also do docker-compose build && docker-compose create && docker-compose start  
1. Or you could do docker-compose up for-the-specific-service // and not the whole system. 

## docker-compose down
1. Opposite of up. Duh. 
1. Stop, delete, and remove all artifacts. 
1. Or you docker-compose stop && docker-compose rm 
1. You could just stop, if it was about saving battery. 

## docker-compose stop 

## docker-compose restart 
1. Same as docker-compose stop && docker-compose start

## docker-compose environment variables and build arguments

1. environment variables
    1. available inside the container

1. build arguments
    1. available only during the build time. NOT inside the container 
    1. build tools version, AWS region etc. 


## docker-compose build arguments

```yaml
version: "3.9"

services: 
    my-service-one:
        build:          # The Context gets its own element now. 
            context: . 
            args:       # There can be any number of arguments. 
                - chunnu=munnu 
                - region=us-east-1
    my-service-two:
        image: "mysql"  // use the latest?? mysql impage from the registry. 
```

## docker-compose environment variables 

```
Logger.log("Logging from environment: {runtime_env}")
```
```
if ( runtime_env != "prod") disable_payments() 
```

```yaml
version: "3.9"

services: 
    my-service-one:
        build:          # The Context gets its own element now. 
            context: . 
            environment:       # Provide a value in this YAML or it will attempt to pick from the host machine. 
                - runtime_env  # In the host machine export runtime_env=dev
                - debug=true    # You could of course provide the value directly in YAML as well.     
    my-service-two:
        image: "mysql"  // use the latest?? mysql impage from the registry. 
        env_file: 
            - ./mysql/env_vars  # provide all the values there instead of providing it here in open text. 
```

1. mysql/env_vars 
```
MYSQL_ROOT_PWD=abracadabra 
```

## docker-compose volumes 
1. Volumes = Persistent container storage 
1. Target = File directory path inside the container where the volume data lives


```yaml
version: "3.9"

services: 
    my-service-two:
        image: "mysql"  // use the latest?? mysql impage from the registry. 
        env_file: 
            - ./mysql/env_vars  # provide all the values there instead of providing it here in open text. 
        volumes: 
            - /var/lib/something        # only Target is provided. No source. 
                                        # A source will be created and a randomly named Volume. 
            - ./mysql:/var/lib/mysql    # There is a Source:Target volume. 
            - ./configurations:/var/lib/configurations:ro # Give a read only access. The default is rw. 

```

1. If you dont want to wrestle with randomly named volumes, create named volumes. 
1. If you dont name the volume, everytime the docker compose up ran, it created a new volume and they never got deleted. 

```yaml
version: "3.9"

services: 
    my-service-two:
        image: "mysql"  // use the latest?? mysql impage from the registry. 
        volumes: 
            - my-volume:/var/lib/something   # using the named volume so a randomly named is not created. 
volumes: 
    my-volume: 

```

1. When docker compose up, copies data from old to new. 
1. When docker compose down --volume, automatically clean any named volume. 



## docker-compose port mapping 

1. Does your Docker Container do anything useful for the outside world? You might have to open a port. 
1. Need to open port for outside communication. 
1. But, there are too many of them and difficult to keep track of the mappings 
1. Also, the same port could be accidentally used and hence .. **Port Collision** 

```yaml
version: "3.9"

services: 
    my-service-two:
        image: "mysql"  // use the latest?? mysql impage from the registry. 
        ports: 
            - "81:80"   # Use quote if port number is less than 60. 
        volumes: 
            - my-volume:/var/lib/something   # using the named volume so a randomly named is not created. 

```

## docker-compose depends_on 

1. Service dependencies, Startup order.
1. Service 1 cant work witout the Service 2. Website can't work without the Database. 
1. docker-componse up and down need to ensure that this dependency is honoured. 

```yaml
version: "3.9"

services: 

my-service-one:
    image: "mysql"  // use the latest?? mysql impage from the registry. 
    depends_on:
        - my-service-two     
my-service-two:
    image: "mysql"  // use the latest?? mysql impage from the registry. 
    volumes: 
        - my-volume:/var/lib/something   # using the named volume so a randomly named is not created. 

```

## docker-compose service profiles

1. Service Profiles = named subset of services 
1. Set 1 - partial overlap - set 2

1. When there are some services that are 
    1. conceptually together as in they are used together 
    1. but techically they dont depend on each other as in it is not as if one is DB to another website. 
    1. also there are various engineering teams who are in charge of various subsets of the services. 
    1. they want to run their pieces and the ones that are dependenencies to them but not others. 

1. Also, while they are distinct subsets, you want them to be on the same docker-compose.yml 
    1. so that at some point of time you can have easeier integration testing. 
    1. some services are dependencies for all sub sets e.g. database etc. 

1. Only up the web_services i.e. the services tagged with the profile web_services. 
```
docker-compose --profile web_services up | down | stop | restart
```

1. Only up the default services i.e. the ones that are not tagged. 
```
docker-compose up | down | stop | restart
```

```yaml
version: "3.9"

services: 
my-service-1:
    image: "mysql"  // use the latest?? mysql impage from the registry. 
    depends_on:
        - my-service-2
        # No profile added. Automatically added to the default profile. 
        # It will run with all service profiles. 
        # Or it will run when you provide no profiles at all 
        # 
my-service-2:
    # Two profiles are added. Will run with either one of them. 
    profiles:          
        - web_services 
        - app_services 
my-service-3:
    # Will run every time the web_services profile is run. Not otherwise. 
    profiles:
        - web_services 
my-service-4:
    profiles:
        - web_services 
my-service-5:
    profiles:
        - app_services 
my-service-6:
    profiles:
        - app_services 
```

## docker-compose multiple compose files 

1. Set 1 - NO overlap - set 2
1. Different environment - local, staging, CI testing. 
1. They will NEVER run on the same host machine in the same time.

1. docker-compose.yaml + docker-compose.override.yaml
    1. array fields ? original + override 
    1. single value ? preference to the override 
    1. docker-compose.yaml ( must be full and valid )
    1. docker-compose.override.yaml ( do not need to be full or valid, just provide the values to be overriden)

1. docker-compose.yaml 
1. docker-compose.local.yaml 
1. docker-compose.integration.yaml 
1. docker-compose.staging.yaml 

``` 
docker-compose -f docker-compose.yaml -f docker-compose.integration.yaml up 
```

